{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install opencv-python\n",
    "# DATASET DOWNLOADED BELOW\n",
    "# https://www.kaggle.com/datasets/alxmamaev/flowers-recognition?resource=download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import glob\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import pathlib\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Conv2D \n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Nicholas Wilcox\n",
    "# final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path/directory for DAISIES\n",
    "daisyDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/daisy\"\n",
    "for images in os.listdir(daisyDir):\n",
    " \n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path/directory for DAND\n",
    "dandDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/dandelion\"\n",
    "for images in os.listdir(dandDir):\n",
    " \n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path/directory for ROSES\n",
    "roseDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/rose\"\n",
    "for images in os.listdir(roseDir):\n",
    " \n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path/directory for SUNFLOWERS\n",
    "sunDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/sunflower\"\n",
    "for images in os.listdir(sunDir):\n",
    " \n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path/directory for TULIPS\n",
    "tulipDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/tulip\"\n",
    "for images in os.listdir(tulipDir):\n",
    " \n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flower categories:\n",
    "# daisy\n",
    "# dandelion\n",
    "# rose\n",
    "# sunflower\n",
    "# tulip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers'))\n",
    "# ignore .DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "z = []\n",
    "x_imageSize = 320\n",
    "y_imageSize = 240\n",
    "#daisyDir = '/Users/nicholaswilcox/Downloads/myFlowers/daisy'\n",
    "#roseDir = '/Users/nicholaswilcox/Downloads/myFlowers/rose'\n",
    "#tulipDir = '/Users/nicholaswilcox/Downloads/myFlowers/tulip'\n",
    "#dandDir = '/Users/nicholaswilcox/Downloads/myFlowers/dandelion'\n",
    "#sunDir = '/Users/nicholaswilcox/Downloads/myFlowers/sunflower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daisy_size = len(daisyDir)\n",
    "# print(daisy_size) -- 47\n",
    "rose_size = len(roseDir)\n",
    "# print(rose_size) -- 46\n",
    "tulip_size = len(tulipDir)\n",
    "# print(tulip_size) -- 47\n",
    "dand_size = len(dandDir)\n",
    "# print(dand_size) -- 52\n",
    "sun_size = len(sunDir)\n",
    "# print(sun_size) -- 51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FUNCTION OF TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignLabel(img, flowerType):\n",
    "    return flowerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDataFunction (flowerType, dir):\n",
    "    os.getcwd()\n",
    "    for img in tqdm(os.listdir(dir)):\n",
    "        label = assignLabel(img, flowerType)\n",
    "        path = os.path.join(dir, img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (x_imageSize, y_imageSize))\n",
    "\n",
    "        x.append(np.array(img))\n",
    "        z.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN DAISY\n",
    "trainDataFunction('daisy', daisyDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN ROSE\n",
    "trainDataFunction('rose', roseDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN TULIP\n",
    "trainDataFunction('tulip', tulipDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN dandelion\n",
    "trainDataFunction('dandelion', dandDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN sunflower\n",
    "trainDataFunction('sunflower', sunDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total of 4317 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some images\n",
    "\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "fig.set_size_inches(15, 15)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        index = rn.randint(0, len(z))\n",
    "        ax[i, j].imshow(x[index])\n",
    "        ax[i, j].set_title('Flower Type: ' + z[index])\n",
    "plt.tight_layout()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Encoder for Y axis to begin one hot encoding process\n",
    "# Used to encode target values such as y, noy x which we already have\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(z)\n",
    "y = to_categorical(y, 5) # create label for num of classes\n",
    "x = np.array(x)\n",
    "x = x/255 # preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLIT INTO TRAINING SETS\n",
    "## 80 20 Training Validation\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.20, random_state = 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seeds\n",
    "\n",
    "np.random.seed(81)\n",
    "rn.seed(81)\n",
    "tf.random.set_seed(81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "DO NOT RERUN ANYTHING ABOVE UNLESS YOU WANT TO WAIT FOR THE DATA TO TRAIN AGAIN\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the CNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'same', activation = 'relu', input_shape = (150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 96, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 96, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "\n",
    "batch_size = 64 \n",
    "# defines the number of samples to work through\n",
    "# before updating the internal model parameters\n",
    "epochs = 50 # start small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "# ReduceLROnPLateau = reduce learning rate when a metric has stoped improving\n",
    "# \n",
    "# Arguments\n",
    "#\n",
    "# monitor: quantity to be monitored.\n",
    "# factor: factor by which the learning rate will be reduced. new_lr = lr * factor.\n",
    "# patience: number of epochs with no improvement after which learning rate will be reduced.\n",
    "# verbose: int. 0: quiet, 1: update messages.\n",
    "# mode: one of {'auto', 'min', 'max'}. In 'min' mode, the learning rate will be reduced when the quantity monitored has stopped decreasing; in 'max' mode it will be reduced when the quantity monitored has stopped increasing; in 'auto' mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "# min_delta: threshold for measuring the new optimum, to only focus on significant changes.\n",
    "# cooldown: number of epochs to wait before resuming normal operation after lr has been reduced.\n",
    "# min_lr: lower bound on the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_acc', factor = 0.2, patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREVENT OVERFITTING: \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center= False,\n",
    "    samplewise_center= False,\n",
    "    featurewise_std_normalization= False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening= False,\n",
    "    rotation_range= 10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "\n",
    ")\n",
    "datagen.fit(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.01),loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "## Why is the flatten the last step?? Why is are the other layers afterwards not being read??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model.fit_generator(datagen.flow(xTrain, yTrain, batch_size=batch_size), epochs = epochs, steps_per_epoch = xTrain.shape[0] // batch_size, verbose = 1, validation_data =  (xTest, yTest), validation_steps = 1 )\n",
    "# Input to reshape is a tensor with 1843200 values, but the requested shape requires a multiple of 7776\n",
    "#\t [[{{node sequential_6/flatten/Reshape}}]] [Op:__inference_train_function_1216]\n",
    "# Photos are about 320x240 pixels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "620970e1359bed47ba0322f021bbea09f3e72c72680ff2ddf45842cd68feab30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
