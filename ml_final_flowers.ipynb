{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------\n",
    "# TRAINING OUR MODEL\n",
    "#-----------------------------------\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import warnings\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import glob\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import pathlib\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daisyDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/daisy\"\n",
    "dandDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/dandelion\"\n",
    "roseDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/rose\"\n",
    "sunDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/sunflower\"\n",
    "tulipDir = \"/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers/tulip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'daisy', 'rose', 'tulip', 'dandelion', 'sunflower']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('/Users/nicholaswilcox/Desktop/DataScience/final/myFlowers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "z = []\n",
    "x_imageSize = 100\n",
    "y_imageSize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignLabel(img, flowerType):\n",
    "    return flowerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDataFunction (flowerType, dir):\n",
    "    os.getcwd()\n",
    "    for img in tqdm(os.listdir(dir)):\n",
    "        label = assignLabel(img, flowerType)\n",
    "        path = os.path.join(dir, img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (x_imageSize, y_imageSize))\n",
    "\n",
    "        x.append(np.array(img))\n",
    "        z.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 764/764 [00:02<00:00, 352.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAIN DAISY\n",
    "trainDataFunction('daisy', daisyDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 784/784 [00:02<00:00, 337.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAIN ROSE\n",
    "trainDataFunction('rose', roseDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984/984 [00:02<00:00, 329.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAIN TULIP\n",
    "trainDataFunction('tulip', tulipDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:03<00:00, 294.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAIN dandelion\n",
    "trainDataFunction('dandelion', dandDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 733/733 [00:02<00:00, 267.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAIN sunflower\n",
    "trainDataFunction('sunflower', sunDir)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total of 4317 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Encoder for Y axis to begin one hot encoding process\n",
    "# Used to encode target values such as y, noy x which we already have\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(z)\n",
    "y = to_categorical(y, 5) # create label for num of classes\n",
    "x = np.array(x)\n",
    "x = x/255 # preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLIT INTO TRAINING SETS\n",
    "## 80 20 Training Validation\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.20, random_state = 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seeds\n",
    "\n",
    "np.random.seed(81)\n",
    "rn.seed(81)\n",
    "tf.random.set_seed(81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny, nz = xTrain.shape\n",
    "d2_xTrain = xTrain.reshape((nsamples,nx*ny*nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3453, 30000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3453, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "d3_xTrain = pca.fit_transform(d2_xTrain)\n",
    "principalDf = pd.DataFrame(data = d3_xTrain\n",
    "             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Define the number of neighbors to use for the KNN algorithm\n",
    "n_neighbors = 5\n",
    "\n",
    "# Load the dataset of images and labels\n",
    "# x = np.array(...)  # this should be a 2D array where each row is an image\n",
    "# y = np.array(...)  # this should be a 1D array of labels corresponding to the images\n",
    "\n",
    "# Create the KNN model\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "# Train the model on the dataset\n",
    "knn.fit(d2_xTrain, yTrain)\n",
    "\n",
    "# Now you can use the trained model to predict labels for new images\n",
    "predictions = knn.predict(d2_xTrain)[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset of images and labels\n",
    "X = np.array(...)  # this should be a 2D array where each row is an image\n",
    "y = np.array(...)  # this should be a 1D array of labels corresponding to the images\n",
    "\n",
    "# Create the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model on the dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# Now you can use the trained model to predict labels for new images\n",
    "predictions = model.predict(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "620970e1359bed47ba0322f021bbea09f3e72c72680ff2ddf45842cd68feab30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
